---
title: DataLoaderノード
description: CSVとParquetファイルをパイプラインに読み込み
---

import { Aside } from '@astrojs/starlight/components';

DataLoaderノードは、ほとんどのパイプラインの開始点です。データファイルを読み込み、下流のノードに処理のために渡します。

## 概要

| プロパティ | 値 |
|-----------|-----|
| **タイプ** | ソースノード |
| **入力** | なし |
| **出力** | DataFrame |
| **対応形式** | CSV、Parquet |

## 設定

### ファイルパス

データファイルへのパス。**Browse**をクリックしてファイルを選択するか、手動でパスを入力。

```
/Users/yourname/Desktop/data.csv
```

### 対応形式

| 形式 | 拡張子 | 備考 |
|------|--------|------|
| CSV | `.csv` | カンマ区切り値 |
| Parquet | `.parquet` | 列指向ストレージ形式 |

<Aside type="tip">
大きなデータセットでは、Parquetファイルの方が読み込みが速く、メモリ使用量も少なくなります。
</Aside>

## 出力

DataLoaderは以下を含むpandas DataFrameを出力：

- ソースファイルの全カラム
- 推論されたデータ型（数値、文字列、日時）
- 元の行順序を維持

## データプレビュー

ファイル選択後、ノードにプレビューが表示：

- **Rows**: 総行数
- **Columns**: カラム名と型
- **Sample**: データの最初の5行

## 使用例

### 基本的な読み込み

1. DataLoaderノードをキャンバスに追加
2. ノードをクリックしてプロパティパネルを開く
3. **Browse**をクリックしてCSVファイルを選択
4. TrainerまたはScriptノードに接続

### 大きなファイル

100MBを超えるファイルの場合：

1. まずParquet形式への変換を検討
2. Scriptノードを使用してデータをサンプリングまたはフィルタリング
3. 読み込み前に利用可能なメモリを確認

## よくある問題

### 「ファイルが見つかりません」

- ファイルパスが正しいか確認
- ファイルが移動または名前変更されていないか確認
- 絶対パス（`/`で始まる）を使用

### 「エンコーディングエラー」

- CSVファイルはUTF-8エンコーディングを使用する必要があります
- ファイルが別のエンコーディングを使用している場合は、まず変換：

```bash
iconv -f ISO-8859-1 -t UTF-8 input.csv > output.csv
```

### 「メモリエラー」

- ファイルが利用可能なRAMに対して大きすぎる
- データをサンプリングするか、より小さなサブセットを使用
- Parquet形式の使用を検討

## 生成されるコード

パイプライン実行時、DataLoaderは以下を生成：

```python
import pandas as pd

# データを読み込み
df = pd.read_csv("/path/to/data.csv")

# 情報を表示
print(f"Loaded {len(df)} rows, {len(df.columns)} columns")
print(df.dtypes)
```

## ベストプラクティス

1. **説明的なファイル名を使用** — `data.csv`ではなく`customer_churn_2024.csv`
2. **データファイルを一貫した場所に保管** — パイプライン作成後はファイルを移動しない
3. **データ品質を確認** — データが正しく読み込まれたかプレビューで確認
4. **大きなファイルにはParquetを使用** — 読み込みが速く、ファイルサイズも小さい

## 関連ノード

- [Trainer](/ja/reference/nodes/trainer/) — 読み込んだデータでモデルを学習
- [Script](/ja/reference/nodes/script/) — カスタムデータ前処理
