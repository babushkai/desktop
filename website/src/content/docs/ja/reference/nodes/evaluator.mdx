---
title: Evaluatorノード
description: メトリクス計算、SHAP説明生成、モデル性能の可視化
---

import { Aside, Tabs, TabItem } from '@astrojs/starlight/components';

Evaluatorノードはモデルタイプを自動検出し、適切なメトリクスを計算します。また、SHAP値、特徴量重要度、部分依存プロットによる包括的なモデル説明可能性も提供します。

## 概要

| プロパティ | 値 |
|-----------|-----|
| **タイプ** | 分析ノード |
| **入力** | 学習済みモデル（Trainerから） |
| **出力** | メトリクス、可視化、説明 |
| **自動検出** | 分類 vs 回帰 |

## メトリクス

Evaluatorはモデルタイプを自動検出し、**Metrics**タブに適切なメトリクスを表示します。

<Tabs>
  <TabItem label="分類">
    | メトリクス | 説明 |
    |-----------|------|
    | **Accuracy** | 正解予測の割合 |
    | **Precision** | 真陽性 / (真陽性 + 偽陽性) |
    | **Recall** | 真陽性 / (真陽性 + 偽陰性) |
    | **F1 Score** | PrecisionとRecallの調和平均 |
    | **混同行列** | 予測vs実際のビジュアルヒートマップ |

    メトリクスは値がラベル付けされた棒グラフで表示されます。
  </TabItem>
  <TabItem label="回帰">
    | メトリクス | 説明 |
    |-----------|------|
    | **R²** | 決定係数（説明された分散） |
    | **MSE** | 平均二乗誤差 |
    | **RMSE** | 二乗平均平方根誤差 |
    | **MAE** | 平均絶対誤差 |

    誤差メトリクスは低いほど良好、R²は高いほど良好。
  </TabItem>
</Tabs>

## モデル説明可能性

Metricsタブの**Explain**ボタンをクリックして説明を生成。Evaluatorは3種類の説明可能性を提供：

### 1. 特徴量重要度（置換）

特徴量をシャッフルしたときの精度低下を測定することで、各特徴量がモデル予測にどれだけ貢献するかを表示。

**可視化：**
- 水平棒グラフ
- エラーバーは±標準偏差を表示
- 上位10特徴量を表示
- 正の値 = 特徴量が有用、負の値 = 特徴量が有害

### 2. SHAP値

SHAP (SHapley Additive exPlanations) は各特徴量の寄与を帰属させることで個々の予測を説明。

**スマートExplainer選択：**

| モデルタイプ | Explainer | 速度 |
|-------------|-----------|------|
| Random Forest、Gradient Boosting | **TreeExplainer** | 高速 |
| 線形/ロジスティック回帰 | **LinearExplainer** | 高速 |
| SVM、KNN、MLP | **KernelExplainer** | 遅い（50サンプルに制限） |

<Aside type="caution">
KernelExplainerはO(n²)の計算量です。SVM、KNN、MLPモデルでは、実行時間を妥当に保つためSHAP分析は50サンプルのみ使用します。
</Aside>

**ビースウォームチャート：**
- 各点 = 1サンプル
- X軸 = SHAP値（予測への影響）
- Y軸 = 特徴量（重要度順にソート）
- 色 = 特徴量値（赤=高、青=低）
- マルチクラス分類用のクラスセレクター

### 3. 部分依存プロット（PDP）

他の特徴量を一定に保ちながら、1つの特徴量を変化させると予測がどう変わるかを表示。

**機能：**
- 予測vs特徴量値の折れ線グラフ
- 個別サンプル用のICE（Individual Conditional Expectation）線
- パフォーマンスのためICE線は50本に制限
- 上位5特徴量が選択可能
- 分類：クラスごとの確率を表示

## Explainパネル

Explainセクションには以下が表示：

1. **プログレスバー** — 3段階：Permutation → SHAP → PDP
2. **特徴量重要度チャート** — 置換ベースの重要度
3. **SHAPビースウォーム** — 特徴量ごとの影響分布
4. **部分依存** — 特徴量関係プロット
5. **サマリー洞察** — 人間が読める解釈

### サマリー洞察

Evaluatorは自然言語の洞察を生成：

> "モデルは'petal_length'に大きく依存しており、予測影響の45%を占めています。"

> "モデルの予測は主に3つの特徴量によって駆動されています：petal_length、petal_width、sepal_length、合わせて影響の87%を占めています。"

洞察は潜在的な問題もフラグ：
- 重要度スコアの高い分散（モデルの不安定性）
- 単一特徴量の支配（潜在的なデータ漏洩）

## 可視化

全チャートはインタラクティブな可視化に**ECharts**を使用：

| チャート | 場所 | 機能 |
|---------|------|------|
| メトリクス棒グラフ | Metricsタブ | 並列比較 |
| 混同行列 | Metricsタブ | カウント付きヒートマップ |
| 特徴量重要度 | Explainセクション | エラー付き水平棒 |
| SHAPビースウォーム | Explainセクション | ツールチップ付きインタラクティブドット |
| PDP折れ線グラフ | Explainセクション | ICE線、クラスセレクター |

## 接続

| 方向 | ノードタイプ |
|------|-------------|
| **入力元** | Trainer、Script（MODEL_FILEを保存する場合） |
| **出力先** | ModelExporter |

## データ永続化

評価結果はデータベースに永続化：

- **メトリクス** — `run_metrics`テーブルに実行IDで保存
- **説明データ** — メトリクステーブルにJSONで保存
- **履歴アクセス** — Runsタブで過去の実行を表示

任意の過去の実行をクリックしてメトリクスを表示し、説明を再生成できます。

## 依存関係

Evaluatorには以下のPythonパッケージが必要：

| パッケージ | 用途 |
|-----------|------|
| `scikit-learn` | メトリクス、置換重要度 |
| `shap` | SHAP値計算 |
| `pandas`、`numpy` | データ処理 |

SHAPがインストールされていない場合、Evaluatorは置換重要度のみにフォールバックします。

## よくある問題

### 「SHAPが利用できません」

SHAPをインストール：
```bash
pip install shap
```

インストールが失敗した場合（コンパイルエラー）：
```bash
xcode-select --install  # まずXcode CLIツールをインストール
pip install shap
```

### SHAPが非常に遅い

SVM、KNN、MLPモデルでは、SHAPは遅いKernelExplainerを使用します。システムは自動的に50サンプルに制限します。それでも遅い場合：
- ツリーベースのモデル（Random Forest、Gradient Boosting）を使用
- SHAPをスキップし、置換重要度のみ使用

### 混同行列が読みにくい

多くのクラスがある場合、行列は大きくなります。フォーカスする点：
- 対角線の値（正解予測）
- 非対角線のクラスター（よくある誤分類）

### メトリクスがおかしい

以下を確認：
- ターゲットカラムが正しく指定されている
- データにリーク（ターゲットと相関する特徴量）がない
- 訓練/テスト分割が適切にランダム化されている

## 関連ノード

- [Trainer](/ja/reference/nodes/trainer/) — 評価するモデルを学習
- [DataSplit](/ja/reference/nodes/datasplit/) — 適切な訓練/テスト分離を確保
- [ModelExporter](/ja/reference/nodes/exporter/) — 評価後にエクスポート
